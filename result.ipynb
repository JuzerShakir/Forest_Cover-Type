{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Forest Cover Type\n",
    "## Supervised Learning, Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Table of Contents\n",
    "\n",
    "- [Description](#description)\n",
    "- [Getting Started](#Getting-Started)\n",
    "    - [Explaination of the Data](#Explaination-of-the-data)\n",
    "- [Data Exploration](#Data-Exploration)\n",
    "    - [Feature Statistics](#Feature-Statistics)\n",
    "        - [Feature Describe](#Feature-Describe)\n",
    "        - [Feature Skew](#Feature-Skew)\n",
    "        - [Class Distribution](#Class-Distribution)\n",
    "    - [Feature Visualization](#Feature-Visualization)\n",
    "        - [Feature Spread](#Feature-Spread)\n",
    "        - [Feature Distribution](#Feature-Distribution)\n",
    "        - [Feature Comparison](#Feature-Comparison)\n",
    "        - [Feature Correlation](#Feature-Correlation)       \n",
    "- [Data Engineering](#Data-Engineering)\n",
    "    - [Observation Cleaning](#Observation-Cleaning)\n",
    "        - [Handling Missing Values](#Handling-Missing-Values)\n",
    "        - [Handling-Duplicates](#Handling-Duplicates)\n",
    "    - [Dimentionality Reduction](#Dimentionality-Reduction)\n",
    "    - [Shuffling](#Shuffling)\n",
    "    - [Train-Test Split](#Train-Test-Split)\n",
    "    - [Feature Scaling](#Feature-Scaling)\n",
    "- [Model Evaluations](#Model-Evaluations)\n",
    "    - [Benchmark Model](#Benchmark-Model)\n",
    "    - [KNN Performance](#KNN-Performance)\n",
    "    - [RF Performance](#RF-Performance)\n",
    "    - [SGDC Performance](#SGDC-Performance) \n",
    "    - [Choosing Model](#Choosing-Model)\n",
    "- [Final Results](#Final-Results)\n",
    "-----\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "A short description I want to give of how I am going to solve this project before starting. Our goal in this project is to classify which forest type it is from the data given.\n",
    "\n",
    "- This study area includes 4 Wilderness Areas located in the Roosevelt National Forest of Northern Colorado. These area represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological process rather than forest management practices.\n",
    "\n",
    "- Each observation is 30m x 30m forest cover type determined from US Forest Service (USFS) Region 2 Resource Information System (RIS) data. Independent variables were derived from the data originally obtained from US Geological Survey (USGS) and USFS data.\n",
    "\n",
    "- I have been given a total of 54 attributes/features, (excluding 1 target variable) these attributes contain Binary and Quantative attributes, and I need to predict which Forest Cover-Type is it from the given features.\n",
    "\n",
    "- I will first explore the data, visualize it, know what the data wants to tell us. Remove any missing values and features that have null values and scale the data within a specific range.\n",
    "\n",
    "- Split the data 75%-25%, train-test set respectively. Will use 10 K-fold Cross Validation on train set.\n",
    "\n",
    "- Feed the training data to the Naive Bayes (Our Benchmark Model) and evaluate the result on the test set.\n",
    "\n",
    "- Training will be done on the Solution Models that I have chose, those are:-\n",
    "    - K-Nearest Neighbour (KNN), \n",
    "    - Random Forest (RF) and \n",
    "    - Stochastic Gradient Descent Classifier (SGDC)\n",
    "    \n",
    "    All these models will be boosted with Adaboost (Adaptive Boosting) boosting algorithm since we have uneven number of observation of classes in the target varaible.\n",
    " \n",
    "- Scores will be evaluated with Accuracy, Precision, Recall and F1 score metrics.\n",
    "\n",
    "- Choosing the best model from above based on metrics scores and testing that model on the test set.\n",
    "\n",
    "- Conclusions\n",
    "\n",
    "Detailed Info regarding the how I am going approach the problem and data summary is given in `proposal.pdf` file. [Visit](https://github.com/JuzerShakir/Forest_Cover-Type/blob/master/proposal.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries for the project\n",
    "import sys # for python library version\n",
    "import numpy as np # for scientific computing\n",
    "import pandas as pd # for data anaysis\n",
    "import matplotlib # for visualization\n",
    "import seaborn as sns # for visualization\n",
    "import sklearn # ML Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Python: {}'.format(sys.version))  # Python version\n",
    "print('numpy: {}'.format(np.__version__))  # Numpy version\n",
    "print('pandas: {}'.format(pd.__version__))  # Pandas version\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))  # Matplotlib version\n",
    "print('seaborn: {}'.format(sns.__version__))  # seaborn version\n",
    "print('sklearn: {}'.format(sklearn.__version__))  # sklearn version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning module\n",
    "import warnings\n",
    "# will ignore any warning from this category\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "First thing first, we need to import the dataset and have a peak at it...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2596</th>\n",
       "      <th>51</th>\n",
       "      <th>3</th>\n",
       "      <th>258</th>\n",
       "      <th>0</th>\n",
       "      <th>510</th>\n",
       "      <th>221</th>\n",
       "      <th>232</th>\n",
       "      <th>148</th>\n",
       "      <th>6279</th>\n",
       "      <th>...</th>\n",
       "      <th>0.34</th>\n",
       "      <th>0.35</th>\n",
       "      <th>0.36</th>\n",
       "      <th>0.37</th>\n",
       "      <th>0.38</th>\n",
       "      <th>0.39</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2596   51   3  258    0   510  221  232  148  6279 ...  0.34  0.35  0.36  \\\n",
       "0  2590   56   2  212   -6   390  220  235  151  6225 ...     0     0     0   \n",
       "1  2804  139   9  268   65  3180  234  238  135  6121 ...     0     0     0   \n",
       "2  2785  155  18  242  118  3090  238  238  122  6211 ...     0     0     0   \n",
       "\n",
       "   0.37  0.38  0.39  0.40  0.41  0.42  5  \n",
       "0     0     0     0     0     0     0  5  \n",
       "1     0     0     0     0     0     0  2  \n",
       "2     0     0     0     0     0     0  2  \n",
       "\n",
       "[3 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the dataset to a variable\n",
    "data = pd.read_csv(\"covtype.data\")\n",
    "\n",
    "# displaying first 3 observations\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data has been imported successfully but there are missing column names. We need to give column names in order to keep track of columns and make sense of features and data we have.\n",
    "\n",
    "The column names are given here on [Kaggle](https://www.kaggle.com/uciml/forest-cover-type-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the data doesn't have column names, we will provide it in a form of list\n",
    "feature_names = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', \n",
    "                 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1', 'Wilderness_Area2', \n",
    "                'Wilderness_Area3', 'Wilderness_Area4', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7',\n",
    "                'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16', \n",
    "                 'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24', 'Soil_Type25', \n",
    "                 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34', \n",
    "                 'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40', 'Cover_Type']\n",
    "\n",
    "# Feeding column names to the data\n",
    "data.columns = feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying first 5 observation\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, Now that makes sense. \n",
    "Now we need to know the number of observations and features we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of the data\n",
    "# where x will be no. of observation\n",
    "# and y will be features including 1 target variable\n",
    "x, y = data.shape\n",
    "\n",
    "print('We have ', x, ' number of observations and ', y-1, ' features for this dataset to predict type of forest cover.')  # removing count of a target variable in 'y'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the datatypes of each feature and see if it needs any processing if the feature is not in its appropriate form.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatypes of features\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well since all are numeric integer and should be so, then we do not need to do any convertions here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaination of the data\n",
    "\n",
    "Our dataset has `54` features, from them `10` are `numeric` and `44` are `catrgorical`. From 44 categorical, `40` are of `Soil_Type` and `4` of `Wilderness_Area`.\n",
    "\n",
    "We have been provided the names of all `Soil_Type` and `Wilderness_Areas` for this dataset. The table below lists all the names with respect to their feature names in the column:\n",
    "\n",
    "This information is available on [kaggle](https://www.kaggle.com/uciml/forest-cover-type-dataset), [UCI](https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.info) and in my [Proposal](https://github.com/JuzerShakir/Forest_Cover-Type/blob/master/proposal.pdf), but for convenience and have documented here too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature Name | Names |\n",
    "| ------------ | ----- |\n",
    "| Wilderness_Area1 | Rawah Wilderness Area |\n",
    "| Wilderness_Area2 | Neota Wilderness Area |\n",
    "| Wilderness_Area3 | Comanche Wilderness Area |\n",
    "| Wilderness_Area4 | Cache La Poudre Wilderness Area |\n",
    "| Soil_Type1 | Cathedral family - Rock outcrop complex, extremely stony |\n",
    "| Soil_Type2 | Vanet - Ratake families complex, very stony |\n",
    "| Soil_Type3 | Haploborolis - Rock outcrop complex, rubbly |\n",
    "| Soil_Type4 | Ratake family - Rock outcrop complex, rubbly |\n",
    "| Soil_Type5 | Vanet family - Rock outcrop complex, rubbly |\n",
    "| Soil_Type6 | Vanet - Wetmore families - Rock outcrop complex, stony |\n",
    "| Soil_Type7 | Gothic family |\n",
    "| Soil_Type8 | Supervisor - Limber families complex |\n",
    "| Soil_Type9 | Troutville family, very stony |\n",
    "| Soil_Type10 | Bullwark - Catamount families - Rock outcrop complex, rubbly |\n",
    "| Soil_Type11 | Bullwark - Catamount families - Rock land complex, rubbly |\n",
    "| Soil_Type12 | Legault family - Rock land complex, stony |\n",
    "| Soil_Type13 | Catamount family - Rock land - Bullwark family complex, rubbly |\n",
    "| Soil_Type14 | Pachic Argiborolis - Aquolis complex |\n",
    "| Soil_Type15 | _unspecified in the USFS Soil and ELU Survey_ |\n",
    "| Soil_Type16 | Cryaquolis - Cryoborolis complex |\n",
    "| Soil_Type17 | Gateview family - Cryaquolis complex |\n",
    "| Soil_Type18 | Rogert family, very stony |\n",
    "| Soil_Type19 | Typic Cryaquolis - Borohemists complex |\n",
    "| Soil_Type20 | Typic Cryaquepts - Typic Cryaquolls complex |\n",
    "| Soil_Type21 | Typic Cryaquolls - Leighcan family, till substratum complex |\n",
    "| Soil_Type22 | Leighcan family, till substratum, extremely bouldery |\n",
    "| Soil_Type23 | Leighcan family, till substratum, - Typic Cryaquolls complex. |\n",
    "| Soil_Type24 | Leighcan family, extremely stony |\n",
    "| Soil_Type25 | Leighcan family, warm, extremely stony |\n",
    "| Soil_Type26 | Granile - Catamount families complex, very stony |\n",
    "| Soil_Type27 | Leighcan family, warm - Rock outcrop complex, extremely stony |\n",
    "| Soil_Type28 | Leighcan family - Rock outcrop complex, extremely stony |\n",
    "| Soil_Type29 | Como - Legault families complex, extremely stony |\n",
    "| Soil_Type30 | Como family - Rock land - Legault family complex, extremely stony |\n",
    "| Soil_Type31 | Leighcan - Catamount families complex, extremely stony |\n",
    "| Soil_Type32 | Catamount family - Rock outcrop - Leighcan family complex, extremely stony |\n",
    "| Soil_Type33 | Leighcan - Catamount families - Rock outcrop complex, extremely stony |\n",
    "| Soil_Type34 | Cryorthents - Rock land complex, extremely stony |\n",
    "| Soil_Type35 | Cryumbrepts - Rock outcrop - Cryaquepts complex |\n",
    "| Soil_Type36 | Bross family - Rock land - Cryumbrepts complex, extremely stony |\n",
    "| Soil_Type37 | Rock outcrop - Cryumbrepts - Cryorthents complex, extremely stony |\n",
    "| Soil_Type38 | Leighcan - Moran families - Cryaquolls complex, extremely stony |\n",
    "| Soil_Type39 | Moran family - Cryorthents - Leighcan family complex, extremely stony |\n",
    "| Soil_Type40 | Moran family - Cryorthents - Rock land complex, extremely stony |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah! I know! Sorry, I didn't get to pick names! But just given here for reference for curious people who might be wondering what type of Wilderness and Soil does the forest have. \n",
    "\n",
    "We will stick to the current feature names and not change it for ease! Later, if necessory, we might take a look at this if we see some feature catch our interests.\n",
    "\n",
    "Just to clarify, the categorical variable we have here is 2. And these alone have 44 features. But an observation can only have presence of any 2 feature from 44, 1 for Soil and 1 for Wilderness. So if an observation has `'1'` in `Wilderness_Area4` and `'1'` in `Soil_Type12`, it means that it's respective Soil and Wilderness is present, while all other 42 features will have `'0'` hence its absence. And this is what a categorical feature means. And also these are `one-hot encoded` for us, so thanks to the authors!\n",
    "\n",
    "Talking about numeric features, 2, `Aspect` and `Slope` have measurement in `degrees` while 3 `Hillshade..` features have values range from `0 to 255` index, descibing summer solstice. Remaining 5 out 10 numeric features have measurement in `Meters`. \n",
    "\n",
    "The target variable `Cover_Type` ranges bewtween integer value `1 - 7` and each number is a key reprsenting names of different forest type. Let's look at what number represents which forest cover types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Key | Name |\n",
    "| --- | ---- |\n",
    "| 1 | Spruce / Fir |\n",
    "| 2 | Lodgepole Pine |\n",
    "| 3 | Ponderosa Pine |\n",
    "| 4 | Cottonwood / Willow |\n",
    "| 5 | Aspen |\n",
    "| 6 | Douglas-fir |\n",
    "| 7 | Krummholz |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will later take a look how many observations are there for each class.\n",
    "\n",
    "Now let's start exploring the data statistically...\n",
    "\n",
    "-------\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "### Feature Statistics\n",
    "\n",
    "#### Feature Describe\n",
    "\n",
    "In the data exploration section, we will split the data in 2 parts. First part will contain all numerical features and second part will contain all binary features of the data. The target variable `Cover_Type` is not included in any of it.\n",
    "\n",
    "**We will look at the statistics of numerical features and extract useful info out of it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all numerical features from data\n",
    "num_fea = data.iloc[:, :10]\n",
    "\n",
    "# extracting all binary features from data\n",
    "binary_fea = data.iloc[:, 10:-1]\n",
    "\n",
    "\n",
    "# statistics of numerical features\n",
    "num_fea.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean of the feature vary from as low as 14 to as high as 2959.\n",
    "\n",
    "- Standard deviation tells us how spread the data is from the mean, here we can see `Horizontal_Distance_To_Roadways` is the most spread out data followed by `Horizontal_Distance_To_Fire_Points` and `Elevation`. The most densed and near to mean is `Slope` followed by all 3 features of `Hillshade`. [Take a look at plot #1](#Feature-Visualization)\n",
    "\n",
    "- All the features have minimum value of `0` except `Elevation` and `Vertical_Distance_To_Hydrology` features. Where `Elevation` has the highest minimum value and `Vertical_Distance_To_Hydrology` has the lowest, being negative.\n",
    "\n",
    "- We can document here in detail for each feature of how spread or dense the data value is between min-25%, 25%-50%, 50%-75% and 75%--max. These are called the percentile. 25% percentile denotes first quaritle, 50% percentile is the median and 75% percentile is the third quartile. We will look in detail with the help of visualization to clearly understand it later in this project. [Take a look at plot #1](#Feature-Visualization)\n",
    "\n",
    "- `Hillshade`s features have similar maximum value of `254` while `Horizontal_Distance_To_Fire_Points` has the highest followed by `Horizontal_Distance_To_Roadways` feature and they also have the highest ranges of all features. `Slope` having lowest maximum value and also being lowest in range followed by `Apsect` feature. \n",
    "\n",
    "\n",
    "The reason some features are so widely spread and having high values and some features don't is because 5 out of 10 variables are measured in meters, includes (`'Elevation', 'Horizontal_Distance_To_Hydrology' , Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', Horizontal_Distance_To_Fire_Points'`), so it makes sense that these have high values and ranges. Features like `Aspect` and `Slope` are measured in degrees so its maximum value can't go above 360. While `Hillshade`s features have can take on max value of 255. All these were discussed before.\n",
    "\n",
    "To help understand this visually, [take a look at plot #1](#Feature-Visualization) and [take a look at plot #4.1](#Feature-Visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taking statistical look at binary or categorical features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics of binary or categorical features\n",
    "binary_fea.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since here all the values can only be either 0 and 1. The mean can tell us useful information here. `Wilderness_Area1` has the highest mean followed by `Wilderness_Area3`, this means that `Wilderness_Area1` has the most presence in the data compared to other Wilderness Areas. In other words, most observation have features either `Wilderness_Area1` or `Wilderness_Area3`. The least amount of observation will be seen from `Wilderness_Area2`. We will visualize this and `Soil_Type` features later for better understanding these data in `Feature Visualization` section. [Take a look at plot #3](#Feature-Visualization)\n",
    "\n",
    "- One more thing to notice here is that when we add all the mean of `Wildernesss_Area`s `0.448864 + 0.051434 + 0.436074 + 0.063627` we get result `0.999999` which is approximately `1`. This actually makes sense because all the observations can be from any one Wilderness area. I have programmed to check whether any obsevation has 2 Soil types at the same time or None for assurance that our data is in appropriate form. I will do this in `Data Engineering` section.\n",
    "\n",
    "- Hence if we look at this in the probability perspective we can say that, the next observation that we get has `44.8%` probability that its been taken from `Wilderness_Area1`, `43.6%` probability that it's taken from `Wilderness_Area3` and so on for others. [Take a look at plot #2](#Feature-Visualization)\n",
    "\n",
    "- We can document same for `Soil_Type`s too.  [Take a look at plot #3](#Feature-Visualization) and [plot #4.2](#Feature-Visualization)\n",
    "\n",
    "By looking at these statistics of two different data types and since the features have different spreads and uneven amount of distribution, we will feature scale these so that all the feature have similar ranges between 0 and 1. Some algorithm are very sensitive to high values hence giving us inapprpraite results while some algorithms are not. Do be on safe side we will feature scale it and we will do this in `Data Engineering` Section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploring Skewness of each features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skew distribution\n",
    "data.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that `Soil_Type15` has the highest positive skewness meaning the mass of the distribution is concentrated to the left and has long tail to the right. This is also called `right skewed distribution`. Where mode of the feature is to the left most followed by median and mean. [Take a look at plot #3](#Feature-Visualization)\n",
    "\n",
    "- `Elevation` and `Hillshade`s having negatively skewed distibution is the opposite in appearance to the positively skewed where mode is to the right most followed by meadian and mean.\n",
    "\n",
    "- ML algothims can be very sensitive to such ranges of data and can give us inappropriate or weak results. Feature Scaling will handle these as discussed earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Distribution:\n",
    "\n",
    "Let's take a look how each class is distributed.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by forest cover type and calculating total occurance\n",
    "data.groupby('Cover_Type').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have uneven samples of forest cover type, where `Lodgepole Pine (2)` has the highest no. of observation followed by `Spruce (1)`. Only these 2 cover types add up to `495,141` number of observations out of `581,011` total which covers approx `85.2%` of data.\n",
    "\n",
    "- Feeding with such uneven distribution of data to an algorithm will not help them learn more about features like `Cottonwood (4)` and `Aspen (5)` where they have least amount of observation as strongly as features with high amount of observations hence making the algorithm weak learners giving low metrics scores. \n",
    "\n",
    "- To avoid this I will apply Adaboost boosting algorithm to our chosen models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enough of looking at bunch of numbers! Lets Visualize them...!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Spread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the spread and outliers of the data of numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####    1    ######\n",
    "# Box and whiskers plot\n",
    "# Spread of numerical features\n",
    "\n",
    "# importing pyplot module from matplotlib to plt\n",
    "plt = matplotlib.pyplot\n",
    "\n",
    "# plot bg\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "#Size of the plot\n",
    "plt.subplots(figsize=(21, 14))\n",
    "\n",
    "# setting color of the plot\n",
    "color = sns.color_palette('pastel')\n",
    "\n",
    "# Using seaborn to plot it horizontally with 'color'\n",
    "sns.boxplot(data = num_fea, orient='h', palette=color)\n",
    "\n",
    "# Uncomment below code to visualize where every single data observation of the features lie in the plot \n",
    "#sns.swarmplot(data = num_fea)  #WARNING THIS WILL TAKE LOTS OF TIME DEPENDING ON CPU POWER AND RAM YOU HAVE  !!\n",
    "\n",
    "# Title of the graph\n",
    "plt.title('Spread of data in Numerical Features', size = 20)\n",
    "\n",
    "# Horizontal axis Label\n",
    "plt.xlabel('No.of Observation', size = 17)\n",
    "# Vertical axis Label\n",
    "plt.ylabel('Features', size = 17)\n",
    "\n",
    "# x-axis label size\n",
    "plt.xticks(size = 17)\n",
    "#y-axis label size\n",
    "plt.yticks(size = 15)\n",
    "\n",
    "# removing the top and right axes spines, which are not needed\n",
    "sns.despine()\n",
    "\n",
    "# display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As explained by me in [feature statistics](#Feature-Statistics), `Slope` is the most squeezed box plot feature! It's densely packed taking on least range compared to all features. Having little range means `mean` and `median` will be quite close and we saw that before in the table, has a difference of approx 1. It does have a few outliers though.\n",
    "\n",
    "- `Aspect` feature is the only one which do not have any outliers having a range of 360. Since both `Aspect` and `Slope` are measured in degrees, `Aspect` takes on much bigger range than `Slope` because it has lowest max score, hence `Aspect` is much less densed than `Slope`. The `first 50%` of the data, from `min to meadian` is more densed than the `last 50%`, its more spread out.\n",
    "\n",
    "- `Hillshade`s feature also having similar plot like `Slope` including many outliers and taking on smaller range. Similiar plot is for `Vertical_Distance_To_Hydrology` except here the minimum value is negative as we had seen in the table.\n",
    "\n",
    "- `Elevation` and `Horizontal_Distance_To_Hydrology` are the only features that doesn't have minimum value of 0. `Elevation` instead is plotted in middle having many outliers too.\n",
    "\n",
    "- `Horizontal_Distance_To_Roadways` is the most spread data of all features because it has the highest standard deviation score followed by `Horizontal_Distance_To_Fire_Points` though this feature has the maximum value. We can see visually only how spread these are and which one is most. `Horizontal_Distance_To_Fire_Points` may be having largest number of outliers I guess from this plot. If we compare these two features, the last 50% of the data of `Horizontal_Distance_To_Roadways` is much more spread and less dense compared to `Horizontal_Distance_To_Fire_Points` , hence having high standard deviation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets plot how `Wilderness_Area`s are distributed. As we saw earlier in [feature statistics](#Feature-Statistics), the mean of `Wilderness_Area1` and `Wilderness_Area3` were highest which meant there presence were high. Now lets see if thats the case, in visuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####    2    #####\n",
    "# Bar plot\n",
    "# Wilderness Area Count\n",
    "\n",
    "# Splitting binary_fea data in 2\n",
    "# Wild_data will have wilderness data\n",
    "# Soil_Data will have Soil data\n",
    "\n",
    "# Splitting\n",
    "Wild_data, Soil_data = binary_fea.iloc[:,:4], binary_fea.iloc[:,4:]\n",
    "\n",
    "# plot bg\n",
    "sns.set_style(\"darkgrid\", {'grid.color': '.1'})\n",
    "\n",
    "# list of colors\n",
    "flatui = [\"#e74c3c\", \"#34495e\", \"#2ecc71\",\"#3498db\"]\n",
    "# using seaborn, passing color to palette\n",
    "color = sns.color_palette(flatui)\n",
    "\n",
    "# Sum the data, plot bar with given size using color defined\n",
    "Wild_data.sum().plot(kind='bar', figsize=(10, 8), color='#34a028')\n",
    "\n",
    "# Title of the graph\n",
    "plt.title('No. of observations of Wilderness Areas', size = 20)\n",
    "\n",
    "# Horizontal axis Label\n",
    "plt.xlabel('Wilderness Areas', size = 17)\n",
    "# Vertical axis Label\n",
    "plt.ylabel('No.of Observation', size = 17)\n",
    "\n",
    "# x-axis label size, setting label rotations\n",
    "plt.xticks(rotation = 'horizontal', size = 14)\n",
    "# y-axis label size\n",
    "plt.yticks(size = 14)\n",
    "\n",
    "# removing the top and right axes spines, which are not needed\n",
    "sns.despine()\n",
    "\n",
    "# display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I had said earlier, `Wilderness_Area1` has the most presence followed by `Wilderness_Area3`, both have quite close observations and so were their mean value. `Wilderness_Area2` having the least observation. Lets see their exact values for precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total count of each Wilderness Area\n",
    "Wild_data.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The difference of observations between `Wilderness_Area1` and `Wilderness_Area3` is approximately `7k`. \n",
    "\n",
    "- `Wilderness_Area2` and `Wilderness_Area4` may seem to have less observation but its not, as they have `~29k` and `~36k` observations respectively. Which is very good amount of observations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now Let's see similar visualization for `Soil Types`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####    3.1    #####\n",
    "# Bar plot\n",
    "# Soil Type Count\n",
    "\n",
    "# plot bg\n",
    "sns.set_style(\"darkgrid\", {'grid.color': '.1'})\n",
    "\n",
    "\n",
    "# Sum the data, plot horizontal bar with given size using color defined\n",
    "Soil_data.sum().plot(kind='bar', figsize=(24, 12), color='#a87539')\n",
    "\n",
    "# Title of the graph\n",
    "plt.title('No. of observations of Soil Types', size = 20)\n",
    "\n",
    "# Horizontal axis Label\n",
    "plt.xlabel('Soil Types', size = 17)\n",
    "# Vertical axis Label\n",
    "plt.ylabel('No.of Observation', size = 17)\n",
    "\n",
    "# x-axis label size, setting label rotations\n",
    "plt.xticks(rotation = 65, size = 15)\n",
    "# y-axis label size\n",
    "plt.yticks(size = 15)\n",
    "\n",
    "# removing the top and right axes spines, which are not needed\n",
    "sns.despine()\n",
    "\n",
    "# display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical description of Highest observation of Soil Type seen\n",
    "Soil_data.loc[:,'Soil_Type29'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looking at the visualization above the first thing I notice that there are visualization of `normal distribution`, `bimodal distribution`, `Unimodal Distribution` and `Left and Right-skewed distribution` showing up in pieces. In short we see all kinds of distributions here!!\n",
    "\n",
    "- Distribution Observation from Left-Right:\n",
    "    - The left-most appears to have mostly Normal distribution (`Soil_Type1` - `Soil_Type6`).\n",
    "    - Unimodal Distribution (`Soil_Type7` - `Soil_Type8`)\n",
    "    - We see a bimodal distribution (`Soil_Type19` - `Soil_Type14`).\n",
    "    - Left Skewed Distribution (`Soil_Type15` - `Soil_Type21`).\n",
    "    - Normal Distribution (`Soil_Type22` - `Soil_Type24`).\n",
    "    - Right Skewed Distribution (`Soil_Type25` - `Soil_Type28`)\n",
    "    - Mixture of Right Skewed and Bimodal (`Soil_Type29` - `Soil_Type33`).\n",
    "    - Normal Distribution (`Soil_Type34` - `Soil_Type35`).\n",
    "    - Normal Distribution (`Soil_Type36` - `Soil_Type37`).\n",
    "    - Right Skewed Distribution (`Soil_Type38` - `Soil_Type40`)\n",
    "    \n",
    "    \n",
    "- The most observation is seen from `Soil_Type29` followed by `Soil_Type23`, `Soil_Type32` and `Soil_Type33`. As from statistical analysis done of `Soil_Type29`, it shows that the mean is `~0.198` which mean it alone has presence in approximately `20%` of observations in our data. It also had the least skewed value of all in `Soil Types` as we had seen earlier in Data Exploration.\n",
    "\n",
    "**Let's see the exact number and descending order of observations of `Soil Types`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####    3.2    #####\n",
    "# Horizontal Bar plot\n",
    "# Soil Type Count\n",
    "\n",
    "# plot bg\n",
    "sns.set_style(\"darkgrid\", {'grid.color': '.1'})\n",
    "\n",
    "# sum Soil data values, and pass it as a series \n",
    "soil_sum = pd.Series(Soil_data.sum())\n",
    "\n",
    "# will sort values in descending order\n",
    "soil_sum.sort_values(ascending = False, inplace = True)\n",
    "\n",
    "# plot horizontal bar with given size using color defined\n",
    "soil_sum.plot(kind='barh', figsize=(23, 17), color= '#a87539')\n",
    "\n",
    "# horizontal bar flips columns in ascending order, this will filp it back in descending order\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Title of the graph\n",
    "plt.title('No. of observations of Soil Types', size = 20)\n",
    "\n",
    "# Horizontal axis Label\n",
    "plt.xlabel('No.of Observation', size = 17)\n",
    "# Vertical axis Label\n",
    "plt.ylabel('Soil Types', size = 17)\n",
    "\n",
    "# x-axis label size, setting label rotations\n",
    "plt.xticks(rotation = 'horizontal', size = 15)\n",
    "# y-axis label size\n",
    "plt.yticks(size = 16)\n",
    "\n",
    "# removing the top and right axes spines, which are not needed\n",
    "sns.despine()\n",
    "\n",
    "# display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact counts of observations of Soil Type\n",
    "soil_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The least observation are of `Soil_Type15` of `3`. Thats why it had most skewed value of all `Soil Types` of `~440` which now makes sense since this feature has value of `0` for all except for `3` observations hence making it densly concentrated towards `0` and long flat tail to the right having a form of `positively skewed distribution` or `Right Skewed Distribution`.\n",
    "\n",
    "- `Soil_Type29` has the highest, `115,246` observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next let's compare each feature in our data to our target variable, visualizing how much dense and distributed each target variable's class is compared to the feature. We will use [Violin Plot](https://datavizcatalogue.com/methods/violin_plot.html) to visualize this, a combination of Box Plot and Density Plot (Histogram).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######    4.1    ########\n",
    "# Violin Plot (Box + Density)\n",
    "# Comparing numerical features with target variable\n",
    "\n",
    "\n",
    "# plot bg\n",
    "sns.set_style(\"darkgrid\", {'grid.color': '.1'})\n",
    "\n",
    "# setting target variable\n",
    "target = data['Cover_Type']\n",
    "\n",
    "# features to be compared with target variable\n",
    "features = num_fea.columns\n",
    "\n",
    "\n",
    "# loop for plotting Violin Plot for each features in the data\n",
    "for i in range(0, len(features)):\n",
    "    \n",
    "    #figure size\n",
    "    plt.subplots(figsize=(16, 11))\n",
    "    \n",
    "    # Plot violin for i feature for every class in target \n",
    "    sns.violinplot(data=num_fea, x=target, y = features[i])\n",
    "    \n",
    "    # x-axis label size\n",
    "    plt.xticks(size = 15)\n",
    "    # y-axis label size\n",
    "    plt.yticks(size = 16)\n",
    "\n",
    "    # Horizontal axis Label\n",
    "    plt.xlabel('Forest Cover Types', size = 17)\n",
    "    # Vertical axis Label\n",
    "    plt.ylabel(features[i], size = 17)\n",
    "  \n",
    "    # display plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can say so much by looking at these plots of each features. Their medians, interquartile range, skewness, density etc. I will only brief those that are intresting and have valueable information to tell us:\n",
    "\n",
    "- `Elevation` takes on different range of values for different forest classes. Most of the forest at the elevation between `2000m - 25000m` are of `class 4 forest type` while `class 3 forest type` has fewer presence of such `elevation`. `Class 7 forest type` have the observations of most elevated trees ranging from as low as `~2800m` to as high as `~3800m`. The `'max'` value in `elevation` belongs to `class 7 forest type`. This is the most important feature since every feature tells different story to different classes of forest cover type hence an important feature for our algorithm.\n",
    "\n",
    "- `Aspect` is the feature that has normal distribution for each class.\n",
    "\n",
    "- `Slope` feature takes on lower values compared to most features as its measured in degrees and least to `Aspect` which is also measured in degrees. It has the `least maximum` value of all features and by looking the plot above we can say that it belongs to `Forest Cover Type 2`. All classes have dense slope observations between `0-20 degrees`.\n",
    "\n",
    "- `Horizontal distance to hydrology` has the `right or positively skewed distribution` where most of the values for all classes are towards `0-50m`.\n",
    "\n",
    "- `Vertical distance to hydrology` is also `positively skewed distribution` but this takes on values much closer to `0` for all classes for most observations.The `highest value` in this feature belongs to `Forest cover type 2`. And this feature also has the `least minimum value` of all features and that also belongs to `class 2 forest type`, hence `class 2` having most range of data oobservations compared to all other classes.\n",
    "\n",
    "- `Hillshade_9am` and `Hillshade_Noon` are `left or negatively skewed distributions` where they take on max value between `200-250 index value` for most observations in each class. While `Hillshade_3pm` has `normal distribution` for all classes.\n",
    "\n",
    "\n",
    "**Now lets see similar visualize for `Wilderness Areas`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######    4.2    ########\n",
    "# Violin Plot (Box + Density)\n",
    "# Comparing Wilderness features with target variable\n",
    "\n",
    "\n",
    "# plot bg\n",
    "sns.set_style(\"darkgrid\", {'grid.color': '.1'})\n",
    "\n",
    "# setting target variable\n",
    "target = data['Cover_Type']\n",
    "# features to be compared with target variable\n",
    "features = Wild_data.columns\n",
    "\n",
    "\n",
    "# loop for plotting Violin Plot for each features in the data\n",
    "for i in range(0, len(features)):\n",
    "    \n",
    "    #figure size\n",
    "    plt.subplots(figsize=(13, 9))\n",
    "    \n",
    "    # Plot violin for i feature for every class in target\n",
    "    sns.violinplot(data = Wild_data, x=target, y = features[i])\n",
    "    \n",
    "    # x-axis label size\n",
    "    plt.xticks(size = 15)\n",
    "    # y-axis label size\n",
    "    plt.yticks(size = 16)\n",
    "\n",
    "    # Horizontal axis Label\n",
    "    plt.xlabel('Forest Cover Types', size = 17)\n",
    "    # Vertical axis Label\n",
    "    plt.ylabel(features[i], size = 17)\n",
    "\n",
    "    # display plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason these plots look so different than before is because these features take on value ranging between `0 and 1`. \n",
    "\n",
    "- `Wilderness Area 1` belong to `forest cover type 1, 2, 5 and 7` while `wilderness area 3` shows presence in `all classes` except `Forest Cover Type 4`.\n",
    "\n",
    "-  Since `Wilderness Area 2 and 4` have less observations, their dense is less on `1` on all classes compared to other two `Wilderness Areas 1 and 3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Now lets visualize `Soil Type`...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######    4.3    ########\n",
    "# Violin Plot (Box + Density)\n",
    "# Comparing Soil features with target variable\n",
    "\n",
    "\n",
    "# plot bg\n",
    "sns.set_style(\"darkgrid\", {'grid.color': '.1'})\n",
    "\n",
    "# setting target variable\n",
    "target = data['Cover_Type']\n",
    "# features to be compared with target variable\n",
    "features = Soil_data.columns\n",
    "\n",
    "\n",
    "# loop for plotting Violin Plot for each features in the data\n",
    "for i in range(0, len(features)):\n",
    "    \n",
    "    #figure size\n",
    "    plt.subplots(figsize=(13, 9))\n",
    "    \n",
    "    # Plot violin for i feature for every class in target    \n",
    "    sns.violinplot(data=Soil_data, x=target, y = features[i])\n",
    "    \n",
    "    # x-axis label size\n",
    "    plt.xticks(size = 15)\n",
    "    # y-axis label size\n",
    "    plt.yticks(size = 16)\n",
    "\n",
    "    # Horizontal axis Label\n",
    "    plt.xlabel('Forest Cover Types', size = 17)\n",
    "    # Vertical axis Label\n",
    "    plt.ylabel(features[i], size = 17)\n",
    "  \n",
    "    # display plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Soil Type 4` is the only Soil Type that has presence in `all classes` of `forest cover types`.\n",
    "\n",
    "- `Soil Type 7, 15 and 37` belong to `forest class 2, 6 and 7` respectively. They also happen to have fewest observations in all Soil Types as seen [here](#Feature-Visualization). Having observations which has presence of either `Soil Type 7, 15 and 37` has most likely chance of being present in `forest class type 2, 6 and 7` respectively. I think this is an important feature though they have less observations but they do give us a valuable information here.\n",
    "\n",
    "- `Forest Cover Type 4` seems to have less presence compared to all classes for `Soil Types`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now Let us see how much each features are correlated with each other...**\n",
    "\n",
    "Since part of our data is binary, we will exclude binary data from our dataset and only find correlation matrix of numerical data becuase correlation requires continous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######    5    #######\n",
    "# Correlation Plot\n",
    "# Correlation of each feature\n",
    "\n",
    "# fig size\n",
    "plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Compute the correlation matrix\n",
    "num_fea_corr = num_fea.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(num_fea_corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Generates heatmap masking the upper triangle and shrinking the cbar\n",
    "sns.heatmap(num_fea_corr, mask=mask, center=0, square=True, annot=True, annot_kws={\"size\": 15}, cbar_kws={\"shrink\": .8})\n",
    "\n",
    "# x-axis label size\n",
    "plt.xticks(size = 13)\n",
    "# y-axis label size\n",
    "plt.yticks(size = 13)\n",
    "\n",
    "# display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Features that have less or no correlation are colored `black` while features with positive correlation are colored `orange` and `blue` for negative correlation.\n",
    "\n",
    "- As we can see from the above figure, correlation values of the features are given in their respective boxes. \n",
    "\n",
    "- `Hillshade_3pm and Hillshade_9am` show highly `negative correlation` while `hillshade_3pm and Aspect` show highest positive correlation.\n",
    "\n",
    "- `Hillshade_3pm and Aspect` also had almost normal distribution compared to forest cover types classes. ([Plot 4.1](#Feature-Visualization))\n",
    "\n",
    "- Other features which correlations are `Vertical and Horizonal Distance to Hydrology`, `Hillshade_3m and Hillshade_Noon`, `Hillshade_9am and Aspect` and `Hillshade_Noon and Slope`. So in total we have `6` pairs of correlation.\n",
    "\n",
    "- Less Correlated value tell us that the features have different valueable information to tell us and model, hence important features for predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting scatter plots of all features that have correlation greater than 0.5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####    6    #####\n",
    "# Scatter Plots\n",
    "# Correlation that have greater than 0.5\n",
    "\n",
    "# plot bg\n",
    "sns.set_style(\"darkgrid\", {'grid.color': '.1'})\n",
    "\n",
    "# giving list of lists\n",
    "# inner lists conatins pairs of feature which have high correlation\n",
    "list_data_cor = [['Aspect','Hillshade_3pm'], ['Aspect', 'Hillshade_9am'], ['Slope', 'Hillshade_Noon'], ['Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology'], \n",
    "                 ['Hillshade_3pm', 'Hillshade_9am'], ['Hillshade_3pm', 'Hillshade_Noon']]\n",
    "\n",
    "\n",
    "for i,j in list_data_cor:\n",
    "    \n",
    "    # fig size\n",
    "    plt.subplots(figsize=(15, 12))\n",
    "    \n",
    "    sns.scatterplot(data = data, x = i, y = j, hue=\"Cover_Type\", legend = 'full', palette='rainbow_r')\n",
    "\n",
    "    # x-axis label size\n",
    "    plt.xticks(size = 15)\n",
    "    # y-axis label size\n",
    "    plt.yticks(size = 15)\n",
    "\n",
    "    # Horizontal axis Label\n",
    "    plt.xlabel(i, size = 17)\n",
    "    # Vertical axis Label\n",
    "    plt.ylabel(j, size = 17)\n",
    "  \n",
    "    # display plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Hillshade_3pm and Aspect` represent relationship of a `sigmoid function`. The data points at the boundaries of the figure mostly belong to `forest cover type class 1` while `class 3` takes on most of datapoints in the figure followed by `forest cover type class 6`. The datapoints when `Hillshade_3pm` is `0` belongs to `class 1,2,3 or 7` regardless of what `Aspect` values it has.\n",
    "\n",
    "- The figure `Hillshade_9am and Aspect` also represent relationship of a `sigmoid function`. `Class type 3` has the highest observation here followed by the `class type 1 and 6`.\n",
    "\n",
    "- `Hillshade_Noon and Slope` have a `'V' shaped` representation. Lower degrees represent `class 4 and 6` while high degree values represent `class 1, 2 and 7` also we can see decrease in `Hillshade_Noon` value as slope increases and it geographically makes sense.\n",
    "\n",
    "- `Vertical and Horizontal Distance to Hydrology` represent a `linear` but spreaded out type, not a single line fit to all datapoints. `Class type 7 and 2` have more observation here and spreaded out while `class type 3 and 6` are densely packed between the range `0-800m` of `Horizontal Distance to Hydrology`.\n",
    "\n",
    "- ` Hilshade_9am and Hillshade_3p`m figure represents relationship of a sliced out part of a circle where top most of the datapoints belong to `class 3` and middle and bottom area belong to rest of the classes.\n",
    "\n",
    "- `Hillshade_Noon and Hillshade_3pm` have similar observation as described before just a difference here is that it's flipped over y-aixs. We also see similar patterns of datapoints too as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now lets move on to the next part of he project, Data Engimeering, where I am going delete columns which has `'0'` value for all observation, delete observation which has null values in any of its features, deleting duplicate entries but keeping first and shuffling all observations. I will also take a look where if any observations is present in more than one type in smae category of Wilderness and Soil Type.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a possibility where we can have an observation where `Soil Type` and `Wilderness Area` are recorded as present for more than one type or maybe none.\n",
    "\n",
    "Below code will show us if we have any.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if any observation have more than 1 presence of Wilderness area at same time or None\n",
    "\n",
    "# Count for more than 1 presence\n",
    "more_count = 0\n",
    "# Count for none presence\n",
    "none_count = 0\n",
    "# total count\n",
    "total = 0\n",
    "\n",
    "#looping through each row of wilderness area column\n",
    "for index, row in Wild_data.iterrows():\n",
    "    # adding the values of each column of that row\n",
    "    total = row.sum(axis=0)\n",
    "    \n",
    "    #checking greater than 1\n",
    "    if total > 1:\n",
    "        # if found, increment count by 1\n",
    "        more_count =+ 1\n",
    "        # reset the total\n",
    "        total = 0\n",
    "        # do not execute code below, start from top\n",
    "        break\n",
    "        \n",
    "    #checking for none   \n",
    "    if total == 0:\n",
    "        # if found, increment count by 1\n",
    "        none_count =+ 1\n",
    "        # reset the total\n",
    "        total = 0      \n",
    "\n",
    "# priting results found\n",
    "print('We have ', more_count, ' observations that shows presence in more than 1 Wilderness Area.')\n",
    "print('We have ' ,none_count, ' observations that shows no presence in any Wilderness Area.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if we have any categorical/binary features that have '0' value throughout all observation... (We had proven that there is no such feature above, Just to make sure )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if any observation have more than 1 presence of Soil Type area at same time or None\n",
    "\n",
    "# Count for more than 1 presence\n",
    "more_count = 0\n",
    "# Count for none presence\n",
    "none_count = 0\n",
    "# total count\n",
    "total = 0\n",
    "\n",
    "#looping through each row of Soil Type area column\n",
    "for index, row in Soil_data.iterrows():\n",
    "    # adding the values of each column of that row\n",
    "    total = row.sum(axis=0)\n",
    "    \n",
    "    #checking greater than 1\n",
    "    if total > 1:\n",
    "        # if found, increment count by 1\n",
    "        more_count =+ 1\n",
    "        # reset the total\n",
    "        total = 0\n",
    "        # do not execute code below, start from top\n",
    "        break\n",
    "        \n",
    "    #checking for none   \n",
    "    if total == 0:\n",
    "        # if found, increment count by 1\n",
    "        none_count =+ 1\n",
    "        # reset the total\n",
    "        total = 0      \n",
    "\n",
    "# priting results found\n",
    "print('We have ', more_count, ' observations that shows presence in more than 1 Soil Type Area.')\n",
    "print('We have ' ,none_count, ' observations that shows no presence in any Soil Type Area.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have **None** to worry about. Thanks to the authors of the data. \n",
    "\n",
    "Another way to approach this problem would be to simply add total counts of each types in Wilderness Area and Soil Type Categories and check if each category is equal to the number of observation in the data we have..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Observation which has any Missing Values in it....**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will delete observation if it has any missing values in any of the features.\n",
    "data.dropna()\n",
    "\n",
    "# shape of the data after deleting missing entries\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO Missing Values...!! That's great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting duplicates, except the first observation\n",
    "data.drop_duplicates(keep='first')\n",
    "\n",
    "# shape of the data after deleting duplicate entries\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO Duplicates too..! Neat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimentionality Reduction\n",
    "\n",
    "- Since we already have lots of observation now to train the model, we also happen to have lots of features. This will make algorithm run very slowly, have difficulty in learning and also tend to overfit in some cases.\n",
    "\n",
    "- We also see above in visualization section that Wilderness Area and Soil Type Area have no category that has no observations of it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Elevation</th>\n",
       "      <td>0.214180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <td>0.109651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <td>0.105740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <td>0.064298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <td>0.059002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspect</th>\n",
       "      <td>0.051435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <td>0.045326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <td>0.043183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <td>0.042510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slope</th>\n",
       "      <td>0.035992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area4</th>\n",
       "      <td>0.022845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type22</th>\n",
       "      <td>0.018727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type10</th>\n",
       "      <td>0.015832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type4</th>\n",
       "      <td>0.014533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type23</th>\n",
       "      <td>0.014367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type38</th>\n",
       "      <td>0.013893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area3</th>\n",
       "      <td>0.013421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type39</th>\n",
       "      <td>0.012516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area1</th>\n",
       "      <td>0.012339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type12</th>\n",
       "      <td>0.011173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type2</th>\n",
       "      <td>0.011109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type40</th>\n",
       "      <td>0.007481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area2</th>\n",
       "      <td>0.006911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type13</th>\n",
       "      <td>0.004941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type32</th>\n",
       "      <td>0.004401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type24</th>\n",
       "      <td>0.004252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type33</th>\n",
       "      <td>0.004137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type29</th>\n",
       "      <td>0.004057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type11</th>\n",
       "      <td>0.003756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type6</th>\n",
       "      <td>0.003733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type31</th>\n",
       "      <td>0.003299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type30</th>\n",
       "      <td>0.002592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type20</th>\n",
       "      <td>0.002130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type3</th>\n",
       "      <td>0.002077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type17</th>\n",
       "      <td>0.001942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type35</th>\n",
       "      <td>0.001864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type19</th>\n",
       "      <td>0.001220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type21</th>\n",
       "      <td>0.001134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type16</th>\n",
       "      <td>0.001051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type34</th>\n",
       "      <td>0.000862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type1</th>\n",
       "      <td>0.000834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type5</th>\n",
       "      <td>0.000816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type27</th>\n",
       "      <td>0.000774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type26</th>\n",
       "      <td>0.000728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type18</th>\n",
       "      <td>0.000724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type37</th>\n",
       "      <td>0.000654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type14</th>\n",
       "      <td>0.000605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type25</th>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type28</th>\n",
       "      <td>0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type36</th>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type9</th>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type8</th>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type7</th>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type15</th>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    importance\n",
       "Elevation                             0.214180\n",
       "Horizontal_Distance_To_Roadways       0.109651\n",
       "Horizontal_Distance_To_Fire_Points    0.105740\n",
       "Horizontal_Distance_To_Hydrology      0.064298\n",
       "Vertical_Distance_To_Hydrology        0.059002\n",
       "Aspect                                0.051435\n",
       "Hillshade_Noon                        0.045326\n",
       "Hillshade_3pm                         0.043183\n",
       "Hillshade_9am                         0.042510\n",
       "Slope                                 0.035992\n",
       "Wilderness_Area4                      0.022845\n",
       "Soil_Type22                           0.018727\n",
       "Soil_Type10                           0.015832\n",
       "Soil_Type4                            0.014533\n",
       "Soil_Type23                           0.014367\n",
       "Soil_Type38                           0.013893\n",
       "Wilderness_Area3                      0.013421\n",
       "Soil_Type39                           0.012516\n",
       "Wilderness_Area1                      0.012339\n",
       "Soil_Type12                           0.011173\n",
       "Soil_Type2                            0.011109\n",
       "Soil_Type40                           0.007481\n",
       "Wilderness_Area2                      0.006911\n",
       "Soil_Type13                           0.004941\n",
       "Soil_Type32                           0.004401\n",
       "Soil_Type24                           0.004252\n",
       "Soil_Type33                           0.004137\n",
       "Soil_Type29                           0.004057\n",
       "Soil_Type11                           0.003756\n",
       "Soil_Type6                            0.003733\n",
       "Soil_Type31                           0.003299\n",
       "Soil_Type30                           0.002592\n",
       "Soil_Type20                           0.002130\n",
       "Soil_Type3                            0.002077\n",
       "Soil_Type17                           0.001942\n",
       "Soil_Type35                           0.001864\n",
       "Soil_Type19                           0.001220\n",
       "Soil_Type21                           0.001134\n",
       "Soil_Type16                           0.001051\n",
       "Soil_Type34                           0.000862\n",
       "Soil_Type1                            0.000834\n",
       "Soil_Type5                            0.000816\n",
       "Soil_Type27                           0.000774\n",
       "Soil_Type26                           0.000728\n",
       "Soil_Type18                           0.000724\n",
       "Soil_Type37                           0.000654\n",
       "Soil_Type14                           0.000605\n",
       "Soil_Type25                           0.000314\n",
       "Soil_Type28                           0.000284\n",
       "Soil_Type36                           0.000138\n",
       "Soil_Type9                            0.000119\n",
       "Soil_Type8                            0.000052\n",
       "Soil_Type7                            0.000039\n",
       "Soil_Type15                           0.000008"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "model = ExtraTreesClassifier(random_state = 53)\n",
    "\n",
    "# feeding all our features to var 'X'\n",
    "X = data.iloc[:,:-1]\n",
    "# feeding our target variable to var 'y'\n",
    "y = data['Cover_Type']\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "ETC_feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "ETC_feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Elevation</th>\n",
       "      <td>0.224383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <td>0.118198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <td>0.111317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <td>0.059384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <td>0.057342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspect</th>\n",
       "      <td>0.046673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area4</th>\n",
       "      <td>0.043899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <td>0.041907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <td>0.041270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <td>0.040011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slope</th>\n",
       "      <td>0.030866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type22</th>\n",
       "      <td>0.016055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type10</th>\n",
       "      <td>0.015688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type38</th>\n",
       "      <td>0.013975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type4</th>\n",
       "      <td>0.013076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type39</th>\n",
       "      <td>0.012135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type12</th>\n",
       "      <td>0.011993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area3</th>\n",
       "      <td>0.011086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type23</th>\n",
       "      <td>0.010365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area1</th>\n",
       "      <td>0.009831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type2</th>\n",
       "      <td>0.009386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type40</th>\n",
       "      <td>0.006414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type32</th>\n",
       "      <td>0.005993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area2</th>\n",
       "      <td>0.005027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type29</th>\n",
       "      <td>0.004848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type13</th>\n",
       "      <td>0.004272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type24</th>\n",
       "      <td>0.004006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type31</th>\n",
       "      <td>0.003619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type33</th>\n",
       "      <td>0.003503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type11</th>\n",
       "      <td>0.002857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type30</th>\n",
       "      <td>0.002713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type6</th>\n",
       "      <td>0.002483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type3</th>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type17</th>\n",
       "      <td>0.001872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type20</th>\n",
       "      <td>0.001757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type35</th>\n",
       "      <td>0.001724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type19</th>\n",
       "      <td>0.001049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type37</th>\n",
       "      <td>0.000896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type16</th>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type1</th>\n",
       "      <td>0.000725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type21</th>\n",
       "      <td>0.000725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type27</th>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type5</th>\n",
       "      <td>0.000595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type34</th>\n",
       "      <td>0.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type14</th>\n",
       "      <td>0.000511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type26</th>\n",
       "      <td>0.000409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type18</th>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type28</th>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type25</th>\n",
       "      <td>0.000164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type9</th>\n",
       "      <td>0.000136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type36</th>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type8</th>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type7</th>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type15</th>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    importance\n",
       "Elevation                             0.224383\n",
       "Horizontal_Distance_To_Roadways       0.118198\n",
       "Horizontal_Distance_To_Fire_Points    0.111317\n",
       "Horizontal_Distance_To_Hydrology      0.059384\n",
       "Vertical_Distance_To_Hydrology        0.057342\n",
       "Aspect                                0.046673\n",
       "Wilderness_Area4                      0.043899\n",
       "Hillshade_Noon                        0.041907\n",
       "Hillshade_3pm                         0.041270\n",
       "Hillshade_9am                         0.040011\n",
       "Slope                                 0.030866\n",
       "Soil_Type22                           0.016055\n",
       "Soil_Type10                           0.015688\n",
       "Soil_Type38                           0.013975\n",
       "Soil_Type4                            0.013076\n",
       "Soil_Type39                           0.012135\n",
       "Soil_Type12                           0.011993\n",
       "Wilderness_Area3                      0.011086\n",
       "Soil_Type23                           0.010365\n",
       "Wilderness_Area1                      0.009831\n",
       "Soil_Type2                            0.009386\n",
       "Soil_Type40                           0.006414\n",
       "Soil_Type32                           0.005993\n",
       "Wilderness_Area2                      0.005027\n",
       "Soil_Type29                           0.004848\n",
       "Soil_Type13                           0.004272\n",
       "Soil_Type24                           0.004006\n",
       "Soil_Type31                           0.003619\n",
       "Soil_Type33                           0.003503\n",
       "Soil_Type11                           0.002857\n",
       "Soil_Type30                           0.002713\n",
       "Soil_Type6                            0.002483\n",
       "Soil_Type3                            0.002304\n",
       "Soil_Type17                           0.001872\n",
       "Soil_Type20                           0.001757\n",
       "Soil_Type35                           0.001724\n",
       "Soil_Type19                           0.001049\n",
       "Soil_Type37                           0.000896\n",
       "Soil_Type16                           0.000751\n",
       "Soil_Type1                            0.000725\n",
       "Soil_Type21                           0.000725\n",
       "Soil_Type27                           0.000713\n",
       "Soil_Type5                            0.000595\n",
       "Soil_Type34                           0.000580\n",
       "Soil_Type14                           0.000511\n",
       "Soil_Type26                           0.000409\n",
       "Soil_Type18                           0.000223\n",
       "Soil_Type28                           0.000169\n",
       "Soil_Type25                           0.000164\n",
       "Soil_Type9                            0.000136\n",
       "Soil_Type36                           0.000070\n",
       "Soil_Type8                            0.000038\n",
       "Soil_Type7                            0.000006\n",
       "Soil_Type15                           0.000005"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state = 53)\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "RFC_feature_importances = pd.DataFrame(model.feature_importances_, index = X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "RFC_feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing at the top 24 feature scores side by side\n",
    "\n",
    "| Features by RF | Score by RF | Features by ETC | Score by ETC |\n",
    "| --------- | -------- | --------- | -------- |\n",
    "| Elevation | 0.224383 | Elevation | 0.214180 |\n",
    "| Horizontal_Distance_To_Roadways | 0.118198 | Horizontal_Distance_To_Roadways | 0.109651 |\n",
    "| Horizontal_Distance_To_Fire_Points | 0.111317 | Horizontal_Distance_To_Fire_Points | 0.105740 |\n",
    "| Horizontal_Distance_To_Hydrology | 0.059384 | Horizontal_Distance_To_Hydrology | 0.064298 |\n",
    "| Vertical_Distance_To_Hydrology | 0.057342 | Vertical_Distance_To_Hydrology | 0.059002 |\n",
    "| Aspect | 0.046673 | Aspect | 0.051435 |\n",
    "| Wilderness_Area4 | 0.043899 | Hillshade_Noon | 0.045326 |\n",
    "| Hillshade_Noon | 0.041907 | Hillshade_3pm | 0.043183 |\n",
    "| Hillshade_3pm | 0.041270 | Hillshade_9am | 0.042510 |\n",
    "| Hillshade_9am | 0.040011 | Slope | 0.035992 |\n",
    "| Slope | 0.030866 | Wilderness_Area4 | 0.022845 |\n",
    "| Soil_Type22 | 0.016055 | Soil_Type22 | 0.018727 |\n",
    "| Soil_Type10 | 0.015688 | Soil_Type10 | 0.015832 |\n",
    "| Soil_Type38 | 0.013975 | Soil_Type4 | 0.014533 |\n",
    "| Soil_Type4 | 0.013076 | Soil_Type23 | 0.014367 |\n",
    "| Soil_Type39 | 0.012135 | Soil_Type38 | 0.013893 |\n",
    "| Soi_Type12 | 0.011993 | Wilderness_Area3 | 0.013421 |\n",
    "| Wilderness_Area3 | 0.011086 | Soil_Type39 | 0.012516 |\n",
    "| Soil_Type_23 | 0.010365 | Wilderness_Area1 | 0.012339 |\n",
    "| Wilderness_Area1 | 0.009831 | Soil_Type12 | 0.011173 |\n",
    "| Soil_Type2 | 0.009386 | Soil_Type2 | 0.011109 |\n",
    "| Soil_Type40 | 0.006414 | Soil_Type40 | 0.007481 |\n",
    "| Soil_Type32 | 0.005993 | Wilderness_Area2 | 0.006911 |\n",
    "| Wilderness_Area2 | 0.005027 | Soil_Type13 | 0.004941 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_1 = data[['Elevation'.'Horizontal_Distance_To_Roadways'.'Horizontal_Distance_To_Fire'.'Horizontal_Distance_To_Hydrology'.'Vertical_Distance_To_Hydrology'.'Aspect'.'Wilderness_Area4'.\n",
    "                 'Hillshade_Noon'.'Hillshade_3pm'.'Hillshade_9am']]\n",
    "\n",
    "sample_2 = data[['Elevation'.'Horizontal_Distance_To_Roadways'.'Horizontal_Distance_To_Fire'.'Horizontal_Distance_To_Hydrology'.'Vertical_Distance_To_Hydrology'.'Aspect'.'Wilderness_Area4'.\n",
    "                 'Hillshade_Noon'.'Hillshade_3pm'.'Hillshade_9am'.'Slope'.'Soil_Type22'.'Soil_Type10'.'Soil_Type4'.'Soil_Type34'.'Soil_Type34'.'Wildernes_Area3'.'Soil_Type12'.'Soil_Type2'.\n",
    "                 'Wilderness_Area1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last 25 observation of our target variable\n",
    "data['Cover_Type'].tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last 25 observation of wilderness feature\n",
    "Wild_data.tail(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go on and change the number of observations. 100, 500, 1000... you will see observations having same class and also same category of `Wilderness Area`. \n",
    "\n",
    "This might affect our model to learn patterns from diffferent classes. To overcome this we will shuffle the data with a fix seed so that each time we run we get similar observation sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing shuffle function from sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# shuffles the data with fix state\n",
    "data = shuffle(data, random_state = 53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after shuffling\n",
    "data['Cover_Type'].tail(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last step before we move to splitting our data to Train-Test Split is to scale the features to some specific range. This is called Feature Scaling. We will scale all feature values to specific range of `0 to 1`. but before we do this we will split the feature and target variables because we dont want to scale our target variable.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing feature scaling function\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# passing range to the function and then save it\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "# apply feature scaling to all features\n",
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our data after feature scaling\n",
    "scaled_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is ready to be splitted into **75%-25% train-test set respectively**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing train-test function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data in 75%-25% train-test respectively with fixed state\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size = 0.25, random_state = 53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of training observation\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of observations our models performance will be testen on\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time to feed our data to the models to see how each models performs using 2 different `evaluation metrics` **`accuracy`** and **`f1 score`** and see which model performs the best. \n",
    "\n",
    "But before that, we will train our data on training set and test the performance of the Benchmark model we discussed about in the start of the project. I will use 10 K-Fold CV to test the performance of our model. I had choosen Naive Bayes Classifier as my benchmark model and I am going to use **`Multimonial Naive Bayes classifier`** since we have a claasification problem to solve.\n",
    "\n",
    "The `Evaluation Metric` I am going to use are `f1 score` and `accuracy` to see how well our model performs.\n",
    "\n",
    "- `Accuracy` is the measure of the correct predicted data divided by total number of observations hence giving a value ranging between `0 and 1`, while `0` is no correctly predicted class whereas `1` is all correctly predicted class. We can multiply the result by `100` to get the accuracy score in terms of percent.\n",
    "\n",
    "- `F1 score` is more useful than accuracy specially in the case where you have uneven amount of class distribution as in our case. It's the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. \n",
    "\n",
    "-  `Accuracy` works best if false positives and false negatives have similar cost. If the cost of false positives and false negatives are very different, itâ€™s better to look at both Precision and Recall or `F1 score`. \n",
    "\n",
    "First I will define a function which will train the `models` using training data and calculate model's performance using `accuracy` and `f1 score`. One sets of instruction for all `models`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### defining function for training models and measuring performance \n",
    "\n",
    "# to measure performance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# for training time\n",
    "import time\n",
    "\n",
    "# fucntion\n",
    "def model_evaluation(clf):\n",
    "    \n",
    "    # passing classifier to a variable\n",
    "    clf = clf\n",
    "    \n",
    "    # records time\n",
    "    start = time.time() \n",
    "    # classifier learning the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    # records the time\n",
    "    end = time.time()\n",
    "    \n",
    "    \n",
    "    # Using 10 K-Fold CV on data, gives peroformance measures\n",
    "    accuracy  = cross_val_score(clf, X_train, y_train, cv = 10, scoring = 'accuracy')\n",
    "    f1_score = cross_val_score(clf, X_train, y_train, cv = 10, scoring = 'f1_macro')\n",
    "    \n",
    "    \n",
    "    # calculating mean of all 10 observation's accuracy and f1, taking percent and rounding to two decimal places\n",
    "    acc_mean = np.round(accuracy.mean() * 100, 2)\n",
    "    f1_mean = np.round(f1_score.mean() * 100, 2)\n",
    "    \n",
    "    # substracts end time with start to give actual time taken in seconds\n",
    "    # divides by 60 to convert in minutes and rounds the answer to two decimal places\n",
    "    t_time = np.round((end - start) / 60, 2)\n",
    "    \n",
    "    \n",
    "    # returns performance measure of the classifier \n",
    "    return acc_mean, f1_mean, t_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see the performance of `MultinomialNB classifier` on given training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Multinomial classifier, one of the Naive Bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# passing the model to function to get performance measures\n",
    "acc_mean, f1_mean, t_time = model_evaluation(MultinomialNB())\n",
    "\n",
    "# results\n",
    "print(\"The accuracy score of Multinomial Naive Bayes Classifier on our training set is\", acc_mean,\"% and f1 score is\", f1_mean,\"% taking\", t_time,\"minutes to train.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It performed better than what I had actually expected in terms of accuracy but it performs poorly in `precision` and `recall` and that's what `f1 score` evaluates for us. \n",
    "\n",
    "Let's now move on to measure performance on the models that I have chose for this problem, they are:\n",
    "\n",
    "    2. K-Nearest Neighbour (KNN) \n",
    "    3. Random Forest (RF)\n",
    "    4. Stochastic Gradient Descent Classifier (SGDC)\n",
    "    \n",
    "In addition to these models, I will be using `Adaboost Classifier` on top of each models since we have uneven amount of class distibutions so it is likely that our model will be weak for less observed points but `Adaboost` will take care of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Support Vector Machine function\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# passing the model SVC as base estimator to the Adaboost Classifier to get performance measures\n",
    "acc_mean, f1_mean = model_evaluation(AdaBoostClassifier(base_estimator = SVC(), random_state = 53, algorithm='SAMME'))\n",
    "\n",
    "# results\n",
    "print(\"The accuracy score of Multinomial Naive Bayes Classifier on our training set is\", acc_mean,\"% and f1 score is\", f1_mean,\"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base estimator of `AdaBoost Classifier` must support calculation of class probability while `SVM` does not support it. To overcome this, we set `Adaboost Classifier's` parameter `'algorithm'` to `'SAMME'`,  which uses discrete boosting algorithm. While default parameter setting of `'algorithm'` is set to `'SAMME.R'` which uses real boosting algorithm, typically converges faster than `SAMME` and achieving a lower test error with fewer boosting iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing K-Nearest Neighbors Classifier function\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# passing the KNN as base estimator to Boosting\n",
    "acc_mean, f1_mean, t_time = model_evaluation(AdaBoostClassifier(base_estimator = KNeighborsClassifier(), random_state = 53))\n",
    "\n",
    "# results\n",
    "print(\"The accuracy score of Multinomial Naive Bayes Classifier on our training set is\", acc_mean,\"% and f1 score is\", f1_mean,\"% taking\", t_time,\"minutes to train.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Boosting classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Random Forest function\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# passing the RF as base estimator to Boosting\n",
    "acc_mean, f1_mean, t_time = model_evaluation(AdaBoostClassifier(base_estimator = RandomForestClassifier(), random_state = 53))\n",
    "\n",
    "# results\n",
    "print(\"The accuracy score of Random Forest Classifier on our training set is\", acc_mean,\"% and f1 score is\", f1_mean,\"% taking\", t_time,\"minutes to train.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDC Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Stochastic Gradient Descent Classifier function\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# passing the RF as base estimator to Boosting\n",
    "acc_mean, f1_mean, t_time = model_evaluation(AdaBoostClassifier(base_estimator = SGDClassifier(), random_state = 53))\n",
    "\n",
    "# results\n",
    "print(\"The accuracy score of Stochastic Gradient Descent Classifier on our training set is\", acc_mean,\"% and f1 score is\", f1_mean,\"% taking\", t_time,\"minutes to train.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing Model\n",
    "\n",
    "Out of 4 Models evaluated above, which performs better? Lets see all the scores of all the models in a table below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Accuracy | F1 Score | Train Time |\n",
    "| ----- | -------- | -------- | ---------- |\n",
    "| KNN | | | |\n",
    "| RF | | | |\n",
    "| SGDC | | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing EM scores for model performance measure\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# definning best chosen classifier\n",
    "clf = AdaBoostClassifier(base_estimator = (), random_state = 53)\n",
    "\n",
    "# predicting unseen data\n",
    "predict = clf.predict(X_test)\n",
    "\n",
    "# calculating accuracy\n",
    "accuracy = accuracy_score(y_test, predict)\n",
    "\n",
    "# calculating f1 score\n",
    "f1_score = f1_score(y_test, predict, average = 'macro')\n",
    "\n",
    "# results\n",
    "print(\"The accuracy score of -- Classifier on our testing set is\", accuracy,\"% and f1 score is\", f1_score,\"%.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
